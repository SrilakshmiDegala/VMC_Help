<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang xml:lang>
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>CMult</title>
  <style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
width: 0.8em;
margin: 0 0.8em 0.2em -1.6em;
vertical-align: middle;
}
.display.math{display: block; text-align: center; margin: 0.5rem auto;}
</style>
  <style type="text/css">body {font-family: arial, helvetica, sans-serif;font-size: 10pt;font-weight: normal;}#title-block-header {display:none;}.level1{margin-left: 0px;}.level2{margin-left: 0px;}.level3{margin-left: 15px;}.level4{margin-left: 15px;}h4 {color:#c06838;}.level5{margin-left: 15px;}.level6{margin-left: 15px;}table {border-spacing: 2px;display: block;font-size: 14px;overflow: auto;width: 100%;margin-bottom: 16px;border-spacing: 0;border-collapse: collapse;}td {padding: 6px 13px;border: 1px solid #dfe2e5;}th {font-weight: 600;padding: 6px 13px;border: 1px solid #dfe2e5;}tr {background-color: #fff;border-top: 1px solid #c6cbd1;}table tr:nth-child(2n) {background-color: #f6f8fa;}.noteBox::before{content: "NOTE:";font-weight: bold;font-size: 11pt;color: #0096C7;}.noteBox{border: 2px solid;border-radius: 5px;padding: 10px;margin: 10px 0;width: 80%;border-color: #0096C7;background-color: rgba(0, 150, 199, 0.1);}</style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">CMult</h1>
</header>
<section id="cmult" class="level1">
<h1>CMult</h1>
<p><img src="data:image/png;base64,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" /></p>
<section id="description" class="level2">
<h2>Description</h2>
<p>The CMult block implements a gain operator, with output equal to the
product of its input by a constant value. This value can be a MATLAB®
expression that evaluates to a constant.</p>
</section>
<section id="parameters" class="level2">
<h2>Parameters</h2>
<section id="basic-tab" class="level3">
<h3>Basic tab</h3>
<p>Parameters specific to the Basic tab are as follows:</p>
<section id="constant-type" class="level4">
<h4>Constant Type</h4>
<section id="fixed-point" class="level5">
<h5>Fixed-point</h5>
<p>Use fixed-point data type.</p>
</section>
<section id="floating-point" class="level5">
<h5>Floating-point</h5>
<p>Use floating-point data type. Can be a constant or an expression. If
the constant cannot be expressed exactly in the specified fixed-point
type, its value is rounded and saturated as needed.</p>
</section>
</section>
<section id="number-of-bits" class="level4">
<h4>Number of bits</h4>
<p>Specifies the bit location of the binary point of the constant, where
bit zero is the least significant bit.</p>
</section>
<section id="binary-point" class="level4">
<h4>Binary point</h4>
<p>Position of the binary point.</p>
</section>
<section id="floating-point-precision" class="level4">
<h4>Floating-point Precision</h4>
<section id="single" class="level5">
<h5>Single</h5>
<p>Specifies single precision (32 bits)</p>
</section>
<section id="double" class="level5">
<h5>Double</h5>
<p>Specifies double precision (64 bits)</p>
</section>
<section id="custom" class="level5">
<h5>Custom</h5>
<p>Activates the field below so you can specify the Exponent width and
the Fraction width.</p>
</section>
</section>
<section id="exponent-width" class="level4">
<h4>Exponent width</h4>
<p>Specify the exponent width.</p>
</section>
<section id="fraction-width" class="level4">
<h4>Fraction width</h4>
<p>Specify the fraction width.</p>
</section>
</section>
<section id="output-tab" class="level3">
<h3>Output tab</h3>
<section id="precision" class="level4">
<h4>Precision</h4>
<p>This parameter allows you to specify the output precision for
fixed-point arithmetic. Floating point arithmetic output will always be
Full precision.</p>
<section id="full" class="level5">
<h5>Full</h5>
<p>The block uses sufficient precision to represent the result without
error.</p>
</section>
<section id="user-defined" class="level5">
<h5>User Defined</h5>
<p>If you do not need full precision, this option allows you to specify
a reduced number of total bits and/or fractional bits.</p>
</section>
</section>
<section id="arithmetic-type" class="level4">
<h4>Arithmetic type</h4>
<section id="signed-2s-comp" class="level5">
<h5>Signed (2’s comp)</h5>
<p>The output is a Signed (2’s complement) number.</p>
</section>
<section id="unsigned" class="level5">
<h5>Unsigned</h5>
<p>The output is an Unsigned number.</p>
</section>
</section>
<section id="fixed-point-precision" class="level4">
<h4>Fixed-point Precision</h4>
<section id="number-of-bits-1" class="level5">
<h5>Number of bits</h5>
<p>Specifies the bit location of the binary point of the output number,
where bit zero is the least significant bit.</p>
</section>
<section id="binary-point-1" class="level5">
<h5>Binary point</h5>
<p>Position of the binary point in the fixed-point output.</p>
</section>
<section id="quantization" class="level5">
<h5>Quantization</h5>
<p>Refer to the section <a href="matlab:helpview(vmcHelp(&#39;name&#39;,&#39;common-options&#39;))">Overflow
and Quantization</a>.</p>
</section>
<section id="overflow" class="level5">
<h5>Overflow</h5>
<p>Refer to the section <a href="matlab:helpview(vmcHelp(&#39;name&#39;,&#39;common-options&#39;))">Overflow
and Quantization</a>.</p>
</section>
</section>
</section>
<section id="implementation-tab" class="level3">
<h3>Implementation tab</h3>
<p>Parameters specific to the Implementation tab are as follows.</p>
<section id="use-behavioral-hdl-description-otherwise-use-core" class="level4">
<h4>Use behavioral HDL description (otherwise use core)</h4>
<p>When selected, Model Composer uses behavioral HDL, otherwise it uses
the LogiCORE™ Multiplier. When this option is not selected (false) Model
Composer internally uses the behavioral HDL model for simulation if any
of the following conditions are true:</p>
<ul>
<li>The constant value is 0 (or is truncated to 0).</li>
<li>The constant value is less than 0 and its bit width is 1.</li>
<li>The bit width of the constant or the input is less than 1 or is
greater than 64.</li>
<li>The bit width of the input data is 1 and its data type is
xlFix.</li>
</ul>
</section>
<section id="implement-using" class="level4">
<h4>Implement using</h4>
<p>Specifies whether to use distributed RAM or block RAM.</p>
</section>
<section id="test-for-optimum-pipelining" class="level4">
<h4>Test for optimum pipelining</h4>
<p>Checks if the Latency provided is at least equal to the optimum
pipeline length supported for the given configuration of the block.
Latency values that pass this test imply that the core produced is
optimized for speed.</p>
<p>Other parameters used by this block are explained in the topic <a href="matlab:helpview(vmcHelp(&#39;name&#39;,&#39;common-options&#39;,&#39;category&#39;,&#39;../GEN/&#39;))">Common
Options in Block Parameter Dialog Boxes</a>.</p>
</section>
</section>
</section>
<section id="logicore-documentation" class="level2">
<h2>LogiCORE™ Documentation</h2>
<p>LogiCORE IP Multiplier v12.0 <a href="https://docs.xilinx.com/access/sources/ud/document?isLatest=true&amp;url=pg108-mult-gen&amp;ft:locale=en-US">(PG108)</a></p>
<p>LogiCORE IP Floating-Point Operator v7.1 <a href="https://docs.xilinx.com/access/sources/ud/document?isLatest=true&amp;url=pg060-floating-point&amp;ft:locale=en-US">(PG060)</a></p>
</section>
</section>
</body>
</html>
